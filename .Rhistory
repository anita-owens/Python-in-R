values_to = "sales")
bookstore %>%
pivot_longer(everything(),
names_to = c(".value", "set"),
names_pattern = "(.)(.)"
)
bookstore %>%
pivot_longer(everything(),
names_to = c(".value", "set")
)
bookstore %>%
pivot_longer(everything(),
names_to = c(".value", "set"),
values_to = "sales"
)
bookstore %>%
mutate(week_number, id = row_number())
bookstore %>%
mutate( week_number = row_number())
bookstore %>%
pivot_longer(everything(), names_to = "location",
values_to = "sales")
bookstore %>%
pivot_longer(everything(), names_to = c("location", "week_number"),
values_to = "sales")
bookstore %>%
pivot_longer(everything(),
names_to = c(".value", "set"),
values_to = "sales"
)
bookstore %>%
pivot_longer(everything(), names_to = "location",
values_to = "sales")
anscombe %>%
pivot_longer(everything(),
names_to = c(".value", "set"),
names_pattern = "(.)(.)"
)
head(anscombe)
bookstore %>%
pivot_longer(everything(),
names_to = c(".value", "set"),
names_pattern = "(.)(.)"
)
anscombe %>%
pivot_longer(everything(),
names_to = c(".value", "location"),
names_pattern = "(.)(.)"
)
bookstore %>%
pivot_longer(everything(),
names_to = c(".value", "location"),
names_pattern = "(.)(.)"
)
bookstore %>%
pivot_longer(everything(), names_to = "location",
values_to = "sales")
bookstore %>%
mutate( week_number = row_number())
bookstore <- bookstore %>%
mutate( week_number = row_number())
bookstore %>%
pivot_longer(everything(), names_to = "location",
values_to = "sales")
bookstore <- read.xlsx("/Users/anitaowens/Documents/Marketing Analytics-Data Driven Techniques with Excel/Excel Files/Chapter 40 Excel Files/OnewayANOVA.xlsx", skipEmptyRows = TRUE)
head(bookstore)
bookstore %>%
mutate(week_number = row_number())
bookstore %>%
pivot_longer(everything(), names_to = "location",
values_to = "sales")
books <- bookstore %>%
mutate(week_number = row_number())
books %>%
pivot_longer(week_number, names_to = "location",
values_to = "sales")
books <- bookstore %>%
mutate(week_number = row_number())
books %>%
pivot_longer(!week_number, names_to = "location",
values_to = "sales")
oneway.test(sales ~ location, data = books)
books <- bookstore %>%
mutate(week_number = row_number())
books <- books %>%
pivot_longer(!week_number, names_to = "location",
values_to = "sales")
oneway.test(sales ~ location, data = books)
lm(sales ~ location, data = books)
lm(sales ~ location + 0, data = books)
oneway.test(sales ~ location, data = books)
lin_reg_model <- lm(sales ~ location + 0, data = books)
summary(lin_reg_model)
books <- bookstore %>%
mutate(week_number = row_number())  %>%
pivot_longer(!week_number, names_to = "location",
values_to = "sales")
books
books <- bookstore %>%
mutate(week_number = row_number())
books <- books %>%
pivot_longer(!week_number, names_to = "location",
values_to = "sales")
books
0.5758>0.05
oneway.test(sales ~ location, data = books)
lin_reg_model <- lm(sales ~ location + 0, data = books, na.rm = TRUE)
summary(lin_reg_model)
is.na(books$sales)
is.na(books$sales)==[0]
books$sales[is.na(books$sales)] <- 0
books
p_value <- anova_model$"Pr(>F)"[1]
anova_model <- oneway.test(sales ~ location, data = books)
lin_reg_model <- lm(sales ~ location + 0, data = books)
summary(lin_reg_model)
p_value <- anova_model$"Pr(>F)"[1]
p_value
anova_model
anova_model$p.value
anova_model <- oneway.test(sales ~ location, data = books)
lin_reg_model <- lm(sales ~ location + 0, data = books)
summary(lin_reg_model)
p_value <- anova_model$p.value
p_value <= .05 #reject null hypothesis if true
(anova_model <- oneway.test(sales ~ location, data = books))
p_value <- anova_model$p.value
p_value <= .05 #reject null hypothesis if true
books <- bookstore %>%
mutate(week_number = row_number())
books <- books %>%
pivot_longer(!week_number, names_to = "location",
values_to = "sales")
books
(anova_model <- oneway.test(sales ~ location, data = books))
p_value <- anova_model$p.value
p_value <= .05 #reject null hypothesis if true
res.ftest <- var.test(sales ~ location, data = books)
books <- bookstore %>%
mutate(week_num = row_number())  %>%
pivot_longer(!week_num, names_to = "location",
values_to = "sales")
books
salt_sales <- salt %>%
mutate(week_num = row_number())  %>%
pivot_longer(!week_num, names_to = "facint",
values_to = "sales")
salt <- read.xlsx("/Users/anitaowens/Documents/Marketing Analytics-Data Driven Techniques with Excel/Excel Files/Chapter 40 Excel Files/Salt.xlsx", skipEmptyRows = TRUE)
str(salt)
head(salt)
salt_sales <- salt %>%
mutate(week_num = row_number())  %>%
pivot_longer(!week_num, names_to = "facint",
values_to = "sales")
salt_sales
salt <- salt %>%
rename(face_one = `1.Facing`,
face_two = `2.Facing`,
face_three = `30.Facing`)
names(salt)
salt_sales <- salt %>%
mutate(week_num = row_number())  %>%
pivot_longer(!week_num, names_to = "facing",
values_to = "sales")
salt_sales
(anova_model <- oneway.test(sales ~ facing, data = salt_sales))
p_value <- anova_model$p.value
p_value <= .05 #reject null hypothesis if true
salt_sales %>%
summarize(sum_sales = sum(sales),
mean_sales = mean(sales),
var_sales = var(sales))
salt_sales %>%
group_by(facing) %>%
summarize(sum_sales = sum(sales),
mean_sales = mean(sales),
var_sales = var(sales))
salt <- read.xlsx("/Users/anitaowens/Documents/Marketing Analytics-Data Driven Techniques with Excel/Excel Files/Chapter 40 Excel Files/Salt.xlsx", skipEmptyRows = TRUE)
str(salt)
head(salt)
#Need to use backticks for exising columns
salt <- salt %>%
rename(face_01 = `1.Facing`,
face_02 = `2.Facing`,
face_03 = `30.Facing`)
names(salt)
salt_sales <- salt %>%
mutate(week_num = row_number())  %>%
pivot_longer(!week_num, names_to = "facing",
values_to = "sales")
salt_sales
(anova_model <- oneway.test(sales ~ facing, data = salt_sales))
p_value <- anova_model$p.value
p_value <= .05 #reject null hypothesis if true
salt_sales %>%
group_by(facing) %>%
summarize(sum_sales = sum(sales),
mean_sales = mean(sales),
var_sales = var(sales))
TukeyHSD(anova_model)
?TukeyHSD
?TukeyHSD
(anova_model <- aov(sales ~ facing, data = salt_sales))
p_value <- anova_model$p.value
p_value <= .05 #reject null hypothesis if true
summary(anova_model)
salt_sales %>%
group_by(facing) %>%
summarize(sum_sales = sum(sales),
mean_sales = mean(sales),
var_sales = var(sales))
TukeyHSD(anova_model)
plot(TukeyHSD(anova_model)) #plot the differences visually
summary(anova_model)
p_value <- anova_model$p.value
p_value <= .05 #reject null hypothesis if true
p_value <= .05 #reject null hypothesis if true
summary(anova_model)
anova_model$residuals
0.00708 <= 0.05
(anova_model <- oneway.test(sales ~ location, data = books))
p_value <- anova_model$p.value
p_value <= .05 #reject null hypothesis if true
0.5758 > 0.05
(anova_model <- oneway.test(sales ~ location, data = books))
p_value <- anova_model$p.value
p_value > 0.05 #no significant improvement
(anova_model <- aov(sales ~ facing, data = salt_sales))
summary(anova_model)
p_value <- anova_model$p.value
p_value > 0.05 #no significant improvement
p_value <- 0.00708
p_value > 0.05 #no significant improvement
?oneway.test
# Install pacman if needed
if (!require("pacman")) install.packages("pacman")
# load packages
pacman::p_load(pacman,
tidyverse, MASS, caret)
#The cats dataset from the MASS package has been preloaded for this exercise.
# Plot the distribution of Hwt
hist(cats$Hwt)
# Assess the normality of Hwt numerically
shapiro.test(cats$Hwt)
#The cats dataset from the MASS package has been preloaded for this exercise.
# Plot the distribution of Hwt
hist(cats$Hwt)
# Assess the normality of Hwt numerically
shapiro.test(cats$Hwt)
# Plot the distribution of the logarithm of Hwt
hist(log(cats$Hwt))
# Assess the normality of the logarithm of Hwt numerically
shapiro.test(log(cats$Hwt))
# Draw a Q-Q plot for Hwt
qqnorm(cats$Hwt)
# Add a reference line
qqline(cats$Hwt)
# Draw a Q-Q plot for logarithm of Hwt
qqnorm(log(cats$Hwt))
# Add a reference line
qqline(log(cats$Hwt))
bookstore <- read.xlsx("/Users/anitaowens/Documents/Marketing Analytics-Data Driven Techniques with Excel/Excel Files/Chapter 40 Excel Files/OnewayANOVA.xlsx", skipEmptyRows = TRUE)
head(bookstore)
bookstore %>%
mutate(week_number = row_number())
books <- bookstore %>%
mutate(week_num = row_number())  %>%
pivot_longer(!week_num, names_to = "location",
values_to = "sales")
books
res.ftest <- var.test(sales ~ location, data = books)
(anova_model <- oneway.test(sales ~ location, data = books))
p_value <- anova_model$p.value
p_value > 0.05 #if true, no significant improvement. if false,
ggplot(data=books, aes(x=location, y=sales)) + geom_boxplot()
# Test normality of extra
shapiro.test(sleep$extra)
# Calculate mean of extra
mean(sleep$extra)
# Derive 95% confidence interval
t.test(sleep$extra)$conf.int
?xts
??xts
library(xts)
# View the structure of gas
str(gas)
# Plot the unrotated data
plot(Bwt ~ Hwt, data = cats)
# Perform PCA
pca_cats <- prcomp(~ Bwt + Hwt, data = cats)
# Compute the summary
summary(pca_cats)
booksales_forecast %>%
group_by(location) %>%
summarize(mean_sales = mean(sales))
(booksales_forecast <- books %>%
group_by(location) %>%
summarize(mean_sales = mean(sales)))
(booksales_forecast <- books %>%
group_by(location) %>%
summarize(mean_sales = mean(sales, na.rm = TRUE)))
(booksales_forecast <- books %>%
group_by(location) %>%
summarize(mean_sales = mean(sales, na.rm = TRUE),
one_sd = sd(sales, na.rm = TRUE))
)
mean(books$sales)
mean(books$sales, na.rm = TRUE)
books %>%
summarize(sum_sales = sum(sales)) %>%
ggplot(aes(x=week, y=sum_sales)) + geom_boxplot()
books %>%
group_by(week) %>%
summarize(sum_sales = sum(sales)) %>%
ggplot(aes(x=week, y=sum_sales)) + geom_boxplot()
books %>%
group_by(week) %>%
summarize(sum_sales = sum(sales)) %>%
ggplot(data = ., aes(x=week, y=sum_sales)) + geom_boxplot()
books %>%
group_by(location) %>%
summarize(sum_sales = sum(sales)) %>%
ggplot(data = ., aes(x=location, y=sum_sales)) + geom_boxplot()
books %>%
group_by(location) %>%
summarize(sum_sales = sum(sales)) %>%
#ggplot(data = ., aes(x=location, y=sum_sales)) + geom_boxplot()
ggplot( aes(x=location, y=sum_sales)) + geom_boxplot()
books_gr <- books %>%
group_by(location) %>%
summarize(sum_sales = sum(sales))
books_gr <- books %>%
group_by(location) %>%
summarize(sum_sales = sum(sales))
ggplot(data = books_gr, aes(x=location, y = sum_sales)) + geom_boxplot()
books_gr
books_gr <- books %>%
group_by(location) %>%
summarize(sum_sales = sum(sales))
books %>%
group_by(location) %>%
summarize(sum_sales = sum(sales, na.rm = TRUE)) %>%
#ggplot(data = ., aes(x=location, y=sum_sales)) + geom_boxplot()
ggplot(data =., aes(x=location, y=sum_sales)) + geom_boxplot()
books_gr <- books %>%
group_by(location) %>%
summarize(sum_sales = sum(sales))
ggplot(data = books_gr, aes(x=location, y = sum_sales)) + geom_boxplot()
ggplot(data = books, aes(x=location, y=sales)) + geom_boxplot()
(anova_model <- oneway.test(sales ~ location, data = books))
p_value <- anova_model$p.value
p_value > 0.05 #if true, no significant improvement. if false,
head(books)
# Test normality across groups
tapply(books$sales, books$location, FUN = shapiro.test)
# Check the homogeneity of variance
bartlett.test(sales ~ location, data = books)
# Perform one-way ANOVA
oneway.test(sales ~ location, data = books, var.equal = TRUE)
# Test normality across groups
tapply(PlantGrowth$weight, PlantGrowth$group, FUN = shapiro.test)
# Check the homogeneity of variance
bartlett.test(weight ~ group, data = PlantGrowth)
# Perform one-way ANOVA
oneway.test(weight ~ group, data = PlantGrowth, var.equal = TRUE)
anova_test <- oneway.test(sales ~ location, data = books, var.equal = TRUE)
summary(anova_test)
(anova_results <- oneway.test(sales ~ location, data = books, var.equal = TRUE))
# Test normality across groups
tapply(books$sales, books$location, FUN = shapiro.test)
# Check the homogeneity of variance
bartlett.test(sales ~ location, data = books)
# Perform one-way ANOVA
(anova_results <- oneway.test(sales ~ location, data = books, var.equal = TRUE))
anova_results$p.value < 0.05 #If true, means are different
(anova_model <- oneway.test(sales ~ location, data = books))
p_value <- anova_model$p.value
p_value > 0.05 #if true, no significant improvement. if false,
(booksales_forecast <- books %>%
group_by(location) %>%
summarize(mean_sales = mean(sales, na.rm = TRUE),
one_sd = sd(sales, na.rm = TRUE))
)
mean(books$sales, na.rm = TRUE)
?read.xlsx
bookstore <- read.xlsx("/Users/anitaowens/Documents/Marketing Analytics-Data Driven Techniques with Excel/Excel Files/Chapter 40 Excel Files/OnewayANOVA.xlsx", skipEmptyRows = TRUE, sheet = "scenario1")
bookstore <- read.xlsx("/Users/anitaowens/Documents/Marketing Analytics-Data Driven Techniques with Excel/Excel Files/Chapter 40 Excel Files/OnewayANOVA.xlsx", skipEmptyRows = TRUE, sheet = "scenario1")
head(bookstore)
colMeans(bookstore, na.rm = TRUE)
bookstore2 <- read.xlsx("/Users/anitaowens/Documents/Marketing Analytics-Data Driven Techniques with Excel/Excel Files/Chapter 40 Excel Files/OnewayANOVA.xlsx", skipEmptyRows = TRUE, sheet = "scenario2")
head(bookstore2)
books2 <- bookstor2e %>%
mutate(week_num = row_number())  %>%
pivot_longer(!week_num, names_to = "location",
values_to = "sales")
books2 <- bookstore2 %>%
mutate(week_num = row_number())  %>%
pivot_longer(!week_num, names_to = "location",
values_to = "sales")
books2
ggplot(data = books2, aes(x=location, y=sales)) + geom_boxplot()
# Test normality across groups
tapply(books2$sales, books2$location, FUN = shapiro.test)
# Check the homogeneity of variance
bartlett.test(sales ~ location, data = books2)
# Perform one-way ANOVA
(anova_results2 <- oneway.test(sales ~ location, data = books2, var.equal = TRUE))
anova_results2$p.value < 0.05 #If true, means are different. reject null hypothesis and alternative hypothesis is true. if false, mean sales are identical in all shelf positions.
ggplot(data = books2, aes(x=location, y=sales)) + geom_boxplot()
(booksales_forecast <- books2 %>%
group_by(location) %>%
summarize(mean_sales = mean(sales, na.rm = TRUE),
one_sd = sd(sales, na.rm = TRUE))
)
aarp_model <- lm(Cost ~ Age + Sex + Coverage, data = AARP)
# Install devtools if necessary
#install.packages("devtools")
# Install statisticalModeling
#devtools::install_github("dtkaplan/statisticalModeling")
library(tidyverse)
library(statisticalModeling)
library(mosaic)
aarp_model <- lm(Cost ~ Age + Sex + Coverage, data = AARP)
summary(aarp_model)
effect_size(aarp_model, ~Age)
effect_size(aarp_model, ~Sex)
effect_size(aarp_model, ~Coverage)
model <- lm(Cost ~ Age + Sex + Coverage, data = AARP)
summary(aarp_model)
effect_size(model, ~Age)
effect_size(model, ~Sex)
effect_size(model, ~Coverage)
effect_size(model, ~ Age)
effect_size(model, ~ Sex)
# To do the comparison, you'll need to multiply the effect size for Age by a number of years. Multiplying years times USD/month per year gives a result in USD/year --- the same units as the effect size for Sex.
68.16025-59.5
#For Age the units are USD/month per year
effect_size(model, ~ Age)
#while for Sex the units are USD/month.
effect_size(model, ~ Sex)
# To do the comparison, you'll need to multiply the effect size for Age by a number of years. Multiplying years times USD/month per year gives a result in USD/year --- the same units as the effect size for Sex.
68.16025-59.5
# To do the comparison, you'll need to multiply the effect size for Age by a number of years. Multiplying years times USD/month per year gives a result in USD/year --- the same units as the effect size for Sex.
(68.16025-59.5)*3.351705
#For Age the units are USD/month per year
effect_size(model, ~ Age)
#while for Sex the units are USD/month.
effect_size(model, ~ Sex)
# To do the comparison, you'll need to multiply the effect size for Age by a number of years. Multiplying years times USD/month per year gives a result in USD/year --- the same units as the effect size for Sex.
(68.16025-59.5)*3.351705
3.351705*12
#For Age the units are USD/month per year
effect_size(model, ~ Age)
#while for Sex the units are USD/month.
effect_size(model, ~ Sex)
# To do the comparison, you'll need to multiply the effect size for Age by a number of years. Multiplying years times USD/month per year gives a result in USD/year --- the same units as the effect size for Sex.
(68.16025-59.5)*3.351705
3.351705*12
(68.16025-59.5)*3.351705
#For Age the units are USD/month per year
effect_size(model, ~ Age)
#while for Sex the units are USD/month.
effect_size(model, ~ Sex)
# To do the comparison, you'll need to multiply the effect size for Age by a number of years. Multiplying years times USD/month per year gives a result in USD/year --- the same units as the effect size for Sex.
10.23278 /3.351705
model <- lm(price ~ living_area + land_value + fireplaces, data = Houses_for_sale)
summary(model)
# Use effect_size()
effect_size(model, ~ living_area)
model <- lm(price ~ living_area + land_value + fireplaces, data = Houses_for_sale)
summary(model)
# Use effect_size()
effect_size(model, ~ living_area)
effect_size(model, ~ land_value)
effect_size(model, ~ fireplaces)
library(shiny)
# Install pacman if needed
if (!require("pacman")) install.packages("pacman")
# load packages
pacman::p_load(pacman,
reticulate)
#Check Anaconda environments
conda_list()
#Declare environment that you want to use
use_condaenv("anaconda3")
#use py_install to install Python packages
py_install(c("pandas", "numpy", "matplotlib", "seaborn", "scikit-learn"))
reticulate::repl_python()
quit
#use py_install to install Python packages
py_install(c("pandas", "numpy", "matplotlib", "seaborn", "scikit-learn", "xlrd"))
reticulate::repl_python()
#use py_install to install Python packages
py_install(c("pandas", "numpy", "matplotlib", "seaborn", "scikit-learn", "xlrd", "openpyxl"))
reticulate::repl_python()
quit
(booksales_forecast <- books2 %>%
group_by(location) %>%
summarize(mean_sales = mean(sales, na.rm = TRUE)
)
# Install pacman if needed
if (!require("pacman")) install.packages("pacman")
# load packages
pacman::p_load(pacman,
reticulate)
#Check Anaconda environments
conda_list()
#Declare environment that you want to use
use_condaenv("anaconda3")
#use py_install to install Python packages
py_install(c("pandas", "numpy", "matplotlib", "seaborn", "scikit-learn"))
reticulate::repl_python()
